{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "5AIXU39OoMvz"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F63Q-YQTmBm4"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-AzXnCcCnHO"
   },
   "outputs": [],
   "source": [
    "import dask.dataframe as dd # use dask to load dataset which exceeds memory\n",
    "data = dd.read_csv('./data.csv', dtype={'attributed_time': 'object'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "id": "51Csrcb5zUaw",
    "outputId": "8c848c62-6026-4d52-ed43-27535c956eec"
   },
   "outputs": [],
   "source": [
    "# obtain counts of each class # require 3 mins to load -- show the imbalance\n",
    "data_0, data_1 = data[\"is_attributed\"].value_counts()\n",
    "\n",
    "#plot\n",
    "fig, ax = plt.subplots()\n",
    "fig.suptitle('Distribution of is_attributed')\n",
    "labels = ['0', '1']\n",
    "counts= [data_0, data_1]\n",
    "ax.set_ylabel('No. of clicks')\n",
    "ax.set_xlabel(\"is_attributed\")\n",
    "bars = ax.bar(labels, counts, color = ('red','green'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZb_dR3xza_2"
   },
   "source": [
    "We observe that:\n",
    "1. Dataset is huge, with more than 175 million observations\n",
    "2. Dataset is highly imbalanced\n",
    "\n",
    "Thus, following will be the steps for data pre-processing:\n",
    "\n",
    "1. Random sampling, where the final dataset we will be using will be approximately 0.25 of the size of the current dataset\n",
    "2. Check for duplicates and remove them (if any)\n",
    "3. Do train-test split\n",
    "4. Undersampling on training set to balance the class distribution\n",
    "5. Deal with missing data (if any)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTmD9NykXYa6"
   },
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bSPR_Z0o3Xjm"
   },
   "source": [
    "### Random Sampling (without replacement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W-A_0Qj8uH9j",
    "outputId": "4af63bf0-fecb-4fde-9ed9-1ad7ab75d1fb"
   },
   "outputs": [],
   "source": [
    "# Read data by chunks of 10 million observations\n",
    "# Sample 2.5 million observations randomly without replacement\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "chunksize = 10**7\n",
    "with pd.read_csv('./data.csv', chunksize=chunksize) as reader:\n",
    "  for chunk in reader:\n",
    "    chunk = chunk.sample(n = int(chunksize/4), replace = False, random_state = 0)\n",
    "    data = pd.concat([data, chunk])\n",
    "    print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iH6Xr7xQ_Z-Y",
    "outputId": "b53b89fe-3950-4c01-8c8c-baf99cedad83"
   },
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "print(data[\"is_attributed\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRUxi0UY3Bf2"
   },
   "source": [
    "### Removing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r8neTobz7ic2",
    "outputId": "b1748f62-2590-4b37-c42a-37ec2decd00b"
   },
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "print('Check whether there are duplicates:', data.duplicated().any())\n",
    "print('Number of duplicates:', sum(data.duplicated(subset=list(data.columns))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3c41x1LH3g2v",
    "outputId": "ed8ffeb5-3a37-4671-86ee-3ca139c9ffb9"
   },
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()\n",
    "\n",
    "print(data.shape)\n",
    "print(data[\"is_attributed\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_CtlEcKW_-J"
   },
   "source": [
    "Since attributed_time is only available when is_attributed=1, this feature will not provide much useful information for analytics. Thus, we decided to drop the attributed_time column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop attributed time column\n",
    "data = data.drop('attributed_time', axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3l2aHg9QBlVz"
   },
   "outputs": [],
   "source": [
    "data.to_csv('./data_sampled.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IbVHL2--6yvM"
   },
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "h7bCLRqAEXHJ"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data_sampled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S_BprSGw5-Rb",
    "outputId": "9a422cdd-0efa-427e-9437-b3d23a008932",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = data.iloc[:,:-1]\n",
    "y = data[\"is_attributed\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9GCrKZQmLVL"
   },
   "source": [
    "### Save sampled train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PW1rps1-mVdF"
   },
   "outputs": [],
   "source": [
    "y_train = pd.DataFrame({'is_attributed': y_train})\n",
    "y_test = pd.DataFrame({'is_attributed': y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wu1Ir_aynAqr"
   },
   "outputs": [],
   "source": [
    "train_sampled = pd.concat([X_train, y_train],  axis=1)\n",
    "test_sampled = pd.concat([X_test, y_test],  axis=1)\n",
    "#train_sampled.to_csv('./train_sampled.csv', index=False)\n",
    "# test_sampled.to_csv('./test_sampled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check; can comment out later\n",
    "train_sampled.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fL19cGhK3w1t"
   },
   "source": [
    "### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JaoHxKSwv9p8"
   },
   "outputs": [],
   "source": [
    "def undersample(train):\n",
    "  train_0 = train[train[\"is_attributed\"] == 0]\n",
    "  train_1 = train[train[\"is_attributed\"] == 1]\n",
    "\n",
    "  train_0_count, train_1_count = train[\"is_attributed\"].value_counts()\n",
    "\n",
    "  # Under-sample class 0\n",
    "  train_0_under = train_0.sample(n = train_1_count, random_state = 0)\n",
    "\n",
    "  # Merge undersampled class 0 and original class 1\n",
    "  train_under = pd.concat([train_0_under, train_1], axis = 0)\n",
    "  return train_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ahS7KHQq5aKJ",
    "outputId": "9c539b5d-5d14-4bdb-929d-d969ac58bfb0"
   },
   "outputs": [],
   "source": [
    "train_undersampled = undersample(train_sampled)\n",
    "\n",
    "print(train_undersampled.shape)\n",
    "print(train_undersampled[\"is_attributed\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "id": "2tvbCZqOzlzN",
    "outputId": "f15ed8f4-0931-4fb5-81d1-0fef2284f4e1"
   },
   "outputs": [],
   "source": [
    "## Save undersampled data\n",
    "train_undersampled.to_csv('./train_undersampled.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCBs140GzzHi"
   },
   "source": [
    "## (Starting Point) Load Undersampled Train CSV Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wffPmEeJ2ZTJ"
   },
   "source": [
    "I have run and saved a copy of the unsampled data, I think can just start from here instead of running the undersampling process everytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "SMaBymzl0Gs1",
    "outputId": "89681114-3d70-41a9-bbb6-56bb1525954d"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train_undersampled.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YUM5vqabfPV2",
    "outputId": "256ac7b8-7423-4f8a-a282-5ec131181dd0"
   },
   "outputs": [],
   "source": [
    "train[\"is_attributed\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine X_train and y_train\n",
    "X_train, y_train = train.iloc[:,:-1], train[\"is_attributed\"]\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zlb3CkFmgEV"
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4UAtOtTgIdN"
   },
   "source": [
    "### 1. Count of unique values of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o28cF0zqgSJd",
    "outputId": "93617db6-255a-466a-fceb-aa98db6ea946"
   },
   "outputs": [],
   "source": [
    "unique_values = []\n",
    "\n",
    "for x in train.iloc[:,:-1].columns:\n",
    "  unique_values.append(len(train[x].unique()))\n",
    "\n",
    "print(len(unique_values))\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "oYm5w90Mij54",
    "outputId": "ca7b54ce-b992-4c88-e18c-268dad72d734"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.suptitle('No. of unique values of each variable')\n",
    "labels = data.iloc[:,:-1].columns.tolist()\n",
    "\n",
    "ax.set_ylabel('No. of unique values')\n",
    "ax.bar(labels, unique_values)\n",
    "\n",
    "for index, value in enumerate(unique_values):\n",
    "    ax.text(x = index, y = value, s=str(value), fontdict=dict(fontsize=10), ha=\"center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nj0kPTdgmqQ1"
   },
   "source": [
    "### 1. Distribution of is_attributed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "id": "u2pjlu_yE-9Q",
    "outputId": "9df6d60a-9241-4ff4-d393-c0a459535c64"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.suptitle('Distribution of is_attributed')\n",
    "labels = ['0', '1']\n",
    "\n",
    "ax.set_ylabel('No. of clicks')\n",
    "ax.bar(labels, data['is_attributed'].value_counts(), color = ('red','green'))\n",
    "\n",
    "for index, value in enumerate(data['is_attributed'].value_counts()):\n",
    "    ax.text(x = index, y = value, s=str(value), fontdict=dict(fontsize=10), ha=\"center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCYCh4J6o0YY"
   },
   "source": [
    "### 2. Time of Day for Clicks (in hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5HjBztqYmO-"
   },
   "source": [
    "Extract day, hour, minute, second from click_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wrtVSKv6Pjlr",
    "outputId": "ab48cab7-767b-4078-c813-1491b901c79c"
   },
   "outputs": [],
   "source": [
    "train_datetime = pd.to_datetime(train['click_time'], format='%Y-%m-%d %H:%M:%S')\n",
    "train['click_time'] = train_datetime\n",
    "train['day'] = train_datetime.dt.day\n",
    "train['hour'] = train_datetime.dt.hour\n",
    "train['minute'] = train_datetime.dt.minute\n",
    "train['second'] = train_datetime.dt.second\n",
    "\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zaOPcJmIT8ZJ"
   },
   "outputs": [],
   "source": [
    "train_hour_0 = train[train[\"is_attributed\"] == 0]['hour']\n",
    "train_hour_1 = train[train[\"is_attributed\"] == 1]['hour']\n",
    "\n",
    "train_min_0 = train[train[\"is_attributed\"] == 0]['minute']\n",
    "train_min_1 = train[train[\"is_attributed\"] == 1]['minute']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "-uCm8WF1Tel3",
    "outputId": "4d56fd1a-b16a-467d-d30d-81f2f55dd809"
   },
   "outputs": [],
   "source": [
    "hours = 24 # 24 hours in a day\n",
    "\n",
    "# Histogram for fraud clicks\n",
    "plt.subplot(2, 1, 1)\n",
    "train_hour_0.hist(bins = hours - 1, color = \"red\")\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"No. of Clicks\")\n",
    "plt.title(\"Distribution of is_attributed = 0 Clicks by Hour\")\n",
    "plt.locator_params(axis = \"x\", nbins = hours)\n",
    "\n",
    "# Histogram for normal clicks\n",
    "plt.subplot(2, 1, 2)\n",
    "train_hour_1.hist(bins = hours - 1, color = \"green\")\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"No. of Clicks\")\n",
    "plt.title(\"Distribution of is_attributed = 1 Clicks by Hour\")\n",
    "plt.locator_params(axis = \"x\", nbins = hours)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "jf959-QbX1bv",
    "outputId": "b0eda4a1-94d3-47be-f042-3618f4d6a081"
   },
   "outputs": [],
   "source": [
    "minutes = 60 # 60 minutes in an hour\n",
    "\n",
    "# Histogram for fraud clicks\n",
    "plt.subplot(2, 1, 1)\n",
    "train_min_0.hist(bins = minutes - 1, color = \"red\")\n",
    "plt.xlabel(\"Minute of Hour\")\n",
    "plt.ylabel(\"No. of Clicks\")\n",
    "plt.title(\"Distribution of is_attributed = 0 Clicks by Minute\")\n",
    "plt.locator_params(axis = \"x\", nbins = minutes)\n",
    "\n",
    "# Histogram for normal clicks\n",
    "plt.subplot(2, 1, 2)\n",
    "train_min_1.hist(bins = minutes - 1, color = \"green\")\n",
    "plt.xlabel(\"Minute of Hour\")\n",
    "plt.ylabel(\"No. of Clicks\")\n",
    "plt.title(\"Distribution of is_attributed = 1 Clicks by Minute\")\n",
    "plt.locator_params(axis = \"x\", nbins = minutes)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0exdWeT-nsd8"
   },
   "source": [
    "### 3. Average Number of Clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pYRKhK7hWAau",
    "outputId": "2a05a6f4-3719-450c-876e-ab445b9180f5"
   },
   "outputs": [],
   "source": [
    "train_0 = train[train[\"is_attributed\"] == 0]\n",
    "train_1 = train[train[\"is_attributed\"] == 1]\n",
    "\n",
    "num_ip_0 = train_0['ip'].nunique()\n",
    "num_ip_1 = train_1['ip'].nunique()\n",
    "\n",
    "num_app_0 = train_0['app'].nunique()\n",
    "num_app_1 = train_1['app'].nunique()\n",
    "\n",
    "num_clicks_0 = train_0.size\n",
    "num_clicks_1 = train_1.size\n",
    "\n",
    "avg_clicks_ip_0 = num_clicks_0 / num_ip_0\n",
    "avg_clicks_ip_1 = num_clicks_1 / num_ip_1\n",
    "\n",
    "avg_clicks_app_0 = num_clicks_0 / num_app_0\n",
    "avg_clicks_app_1 = num_clicks_1 / num_app_1\n",
    "\n",
    "print(num_ip_0, num_ip_1)\n",
    "print(num_app_0, num_app_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "xJNgybFFymJI",
    "outputId": "41639bce-259a-4f5e-c0d3-f1ba456fa481"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.suptitle('Average number of clicks per IP address')\n",
    "labels = ['0', '1']\n",
    "\n",
    "ax.set_ylabel('No. of clicks')\n",
    "ax.bar(labels, (avg_clicks_ip_0, avg_clicks_ip_1), color = ('red','green'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfS1HlSlahMZ"
   },
   "source": [
    "Great difference between the two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "yhSYhsT2ypqg",
    "outputId": "9c4b3f41-d539-479a-e1b0-240250266b5f"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.suptitle('Average number of clicks per app')\n",
    "labels = ['0', '1']\n",
    "\n",
    "ax.set_ylabel('No. of clicks')\n",
    "ax.bar(labels, (avg_clicks_app_0, avg_clicks_app_1), color = ('red','green'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1ZzLMv7m6kj"
   },
   "source": [
    "### 4. Distribution of Device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_kCZXPRo0G75"
   },
   "outputs": [],
   "source": [
    "fraud_data = train[train[\"is_attributed\"] == 0]\n",
    "notfraud_data = train[train[\"is_attributed\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQ0DjYtHzKjt"
   },
   "outputs": [],
   "source": [
    "device_labels = sorted(train[\"device\"].unique().tolist())\n",
    "device_fraud = []\n",
    "device_notfraud = []\n",
    "\n",
    "for device in device_labels:\n",
    "  device_fraud.append(len(fraud_data[fraud_data[\"device\"] == device]))\n",
    "  device_notfraud.append(len(notfraud_data[notfraud_data[\"device\"] == device]))\n",
    "\n",
    "device_labels = [str(x) for x in device_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 941
    },
    "id": "ICdSuG3cg03r",
    "outputId": "4c07b275-6185-42b1-d8e1-77dae2bb8fab"
   },
   "outputs": [],
   "source": [
    "# Not fradulent\n",
    "plt.figure(figsize = (20, 7))\n",
    "plt.bar(x = device_labels,\n",
    "        height = device_notfraud,\n",
    "        color = \"blue\")\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title(\"Distribution of Devices for non-fraudlent cases\", fontsize = 16) \n",
    "plt.xlabel(\"Device ID\", fontsize = 12)\n",
    "\n",
    "  # Option 1: Using normal scale  \n",
    "plt.ylabel(\"Count\", fontsize = 12)\n",
    "\n",
    "  # Option 2: Using log scale\n",
    "# plt.yscale('log')\n",
    "# plt.ylabel(\"Log of Count\", fontsize = 12)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Fradulent\n",
    "plt.figure(figsize = (20, 7))\n",
    "plt.bar(x = device_labels,\n",
    "        height = device_fraud,\n",
    "        color = 'red')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title(\"Distribution of Devices for fradulent cases\", fontsize = 16) \n",
    "plt.xlabel(\"Device ID\", fontsize = 12)\n",
    "\n",
    "  # Option 1: Using normal scale \n",
    "plt.ylabel(\"Count\", fontsize = 12)\n",
    "\n",
    "  # Option 2: Using log scale\n",
    "# plt.yscale('log')\n",
    "# plt.ylabel(\"Log of Count\", fontsize = 12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5o9JwbtkzVk_",
    "outputId": "b63c46fe-79f1-46d0-d0b1-c27fe74ce4be"
   },
   "outputs": [],
   "source": [
    "# For checks\n",
    "print(\"Device Labels are: \", \"\\n\", device_labels)\n",
    "print(\"Non fradulent counts are: \", \"\\n\", device_notfraud)\n",
    "print(\"Fradulent counts are: \", \"\\n\", device_fraud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UyyQHZiUnItg"
   },
   "source": [
    "### 5. Distribution of Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A08l3_c40QHf"
   },
   "outputs": [],
   "source": [
    "channel_labels = sorted(train[\"channel\"].unique().tolist())\n",
    "channel_fraud = []\n",
    "channel_notfraud = []\n",
    "\n",
    "for channel in channel_labels:\n",
    "  channel_fraud.append(len(fraud_data[fraud_data[\"channel\"] == channel]))\n",
    "  channel_notfraud.append(len(notfraud_data[notfraud_data[\"channel\"] == channel]))\n",
    "\n",
    "channel_labels = [str(x) for x in channel_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 870
    },
    "id": "jxaSmrVa1ZBZ",
    "outputId": "721636c4-eeb5-4634-96aa-ed1f94576c57"
   },
   "outputs": [],
   "source": [
    "# Not fradulent\n",
    "plt.figure(figsize = (25, 7))\n",
    "plt.bar(x = channel_labels,\n",
    "        height = channel_notfraud,\n",
    "        color = \"blue\")\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title(\"Distribution of Channels for non-fraudlent cases\", fontsize = 16) \n",
    "plt.xlabel(\"Channel ID\", fontsize = 12)\n",
    "plt.ylabel(\"Count\", fontsize = 12)\n",
    "plt.show()\n",
    "\n",
    "# Fradulent\n",
    "plt.figure(figsize = (25, 7))\n",
    "plt.bar(x = channel_labels,\n",
    "        height = channel_fraud,\n",
    "        color = 'red')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title(\"Distribution of Channels for fradulent cases\", fontsize = 16) \n",
    "plt.xlabel(\"Channel ID\", fontsize = 12)\n",
    "plt.ylabel(\"Count\", fontsize = 12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jx2F_KGl0QB1",
    "outputId": "f0057f0b-a2d0-4724-fd7b-be697572bb68"
   },
   "outputs": [],
   "source": [
    "# For checks\n",
    "print(\"Channel Labels are: \", \"\\n\", channel_labels)\n",
    "print(\"Non fradulent counts are: \", \"\\n\", channel_notfraud)\n",
    "print(\"Fradulent counts are: \", \"\\n\", channel_fraud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7nKcvZNnOse"
   },
   "source": [
    "### 6. Distribution of IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eyr4xOF917-8"
   },
   "outputs": [],
   "source": [
    "ip_labels = sorted(train[\"ip\"].unique().tolist())\n",
    "ip_fraud = []\n",
    "ip_notfraud = []\n",
    "\n",
    "for ip in ip_labels:\n",
    "  ip_fraud.append(len(fraud_data[fraud_data[\"ip\"] == ip]))\n",
    "  ip_notfraud.append(len(notfraud_data[notfraud_data[\"ip\"] == ip]))\n",
    "\n",
    "ip_labels = [str(x) for x in ip_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "xmI0ouDm2vsf",
    "outputId": "76240941-4080-4700-9af1-3e59d7af8114"
   },
   "outputs": [],
   "source": [
    "# Not fradulent\n",
    "plt.figure(figsize = (25, 7))\n",
    "plt.bar(x = ip_labels,\n",
    "        height = ip_notfraud,\n",
    "        color = \"blue\")\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title(\"Distribution of IP addresses for non-fraudlent cases\", fontsize = 16) \n",
    "plt.xlabel(\"IP Adress\", fontsize = 12)\n",
    "plt.ylabel(\"Count\", fontsize = 12)\n",
    "plt.show()\n",
    "\n",
    "# Fradulent\n",
    "plt.figure(figsize = (25, 7))\n",
    "plt.bar(x = ip_labels,\n",
    "        height = ip_fraud,\n",
    "        color = 'red')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title(\"Distribution of IP addresses for fradulent cases\", fontsize = 16) \n",
    "plt.xlabel(\"Channel ID\", fontsize = 12)\n",
    "plt.ylabel(\"Count\", fontsize = 12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-sh9lxl2J2u"
   },
   "outputs": [],
   "source": [
    "# For checks\n",
    "print(\"IP Labels are: \", \"\\n\", ip_labels)\n",
    "print(\"Non fradulent counts are: \", \"\\n\", ip_fraud)\n",
    "print(\"Fradulent counts are: \", \"\\n\", ip_notfraud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sllpN7fRnVBb"
   },
   "source": [
    "### 7. Distribution of OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 892
    },
    "id": "2XkGSbwBn7Bj",
    "outputId": "56a060af-ce49-4492-e865-2e50238cb889"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "ax = sns.countplot(x=\"os\", hue=\"is_attributed\", data=train)\n",
    "ax.set_yscale(\"log\")\n",
    "ax.legend(loc=\"upper right\")\n",
    "# generate graph xlabels\n",
    "attributed_os = train[train[\"is_attributed\"]==1][\"os\"].unique()\n",
    "os_xlabels = [str(i) if i in attributed_os else \"\" for i in sorted(train[\"os\"].unique())]\n",
    "ax.set_xticklabels(os_xlabels, fontsize=8)\n",
    "ax.set_title(\"Distribution of OS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "TlybqIvE0ZlL",
    "outputId": "e0011cd2-3106-40a1-ab59-b5288799bb4f"
   },
   "outputs": [],
   "source": [
    "proportion = train[['os', 'is_attributed']].groupby('os', as_index=False).mean().sort_values('is_attributed', ascending=False)\n",
    "counts = train[['os', 'is_attributed']].groupby('os', as_index=False).count().sort_values('is_attributed', ascending=False)\n",
    "merge = counts.merge(proportion, on='os', how='left')\n",
    "merge.columns = ['os', 'click_count', 'conversion_rate']\n",
    "merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "u884900I2K9t",
    "outputId": "263e724c-b6bc-445c-f848-f4ba248bafb9"
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "l1 = ax.plot(merge.click_count, color=\"red\", label=\"Count of Clicks\")\n",
    "#ax.set_yscale(\"log\")\n",
    "ax.set_ylabel(\"Count of Clicks\")\n",
    "\n",
    "ax2=ax.twinx()\n",
    "l2 = ax2.plot(merge.conversion_rate, color=\"blue\", label=\"Conversion Rate\")\n",
    "ax2.set_ylabel(\"Conversion Rate\")\n",
    "\n",
    "lns = l1+l2\n",
    "labs = [l.get_label() for l in lns]\n",
    "ax.legend(lns, labs, loc=\"best\")\n",
    "ax.set_xlabel(\"index\")\n",
    "ax.set_title(\"Conversion Rate over Count of OS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0OUhd_9enmJp"
   },
   "source": [
    "### 8. Average Time between Clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jx3A1mUxqo3G"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "sorted_ip = sorted(train[\"ip\"].unique())\n",
    "sorted_ip_attributed = sorted(train[train[\"is_attributed\"]==1][\"ip\"].unique())\n",
    "click_average_time_0 = []\n",
    "click_average_time_1 = []\n",
    "\n",
    "def get_average_time(click_time):\n",
    "  count = len(click_time)\n",
    "  # assign -1 if click once\n",
    "  if count <= 1:\n",
    "    return -1\n",
    "  else:\n",
    "    start_time = datetime.strptime(click_time[0], '%Y-%m-%d %H:%M:%S')\n",
    "    end_time = datetime.strptime(click_time[count-1], '%Y-%m-%d %H:%M:%S')\n",
    "    difference = (end_time - start_time).total_seconds()/60\n",
    "    if difference == 0:\n",
    "      return 0\n",
    "    else:\n",
    "      return difference/(count-1)\n",
    "\n",
    "for ip in sorted_ip:\n",
    "  click_time = sorted(train[train[\"ip\"]==ip][\"click_time\"].values)\n",
    "  average_time = get_average_time(click_time)\n",
    "  # remove -1 values for better visualization\n",
    "  if average_time != -1:\n",
    "    if ip in sorted_ip_attributed:\n",
    "      click_average_time_1.append(average_time)\n",
    "    else:\n",
    "      click_average_time_0.append(average_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 893
    },
    "id": "HYFQ2tDp8ttH",
    "outputId": "d8ac8acd-dc33-411e-e74c-ef2e85826f65"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "ax = sns.histplot([click_average_time_0, click_average_time_1], multiple = \"stack\")\n",
    "ax.set_xlabel(\"Time (in minutes)\")\n",
    "ax.set_title(\"Average Time between Clicks\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 893
    },
    "id": "fqBbTkHFhLJJ",
    "outputId": "0268865e-7d09-48fc-9d04-ac0c1faffe73"
   },
   "outputs": [],
   "source": [
    "rng = range(int(min(click_average_time_0)), int(max(click_average_time_0)) + 60, 60)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(20, 15))\n",
    "# Histogram for fraud clicks\n",
    "sns.histplot(click_average_time_0, ax = axes[0], bins = rng, color = \"red\")\n",
    "axes[0].set_xlabel(\"Time (in minutes)\")\n",
    "axes[0].set_title(\"Average Time between Fraud Clicks\")\n",
    "\n",
    "# Histogram for normal clicks\n",
    "sns.histplot(click_average_time_1, ax = axes[1], bins = rng, color = \"green\")\n",
    "axes[1].set_xlabel(\"Time (in minutes)\")\n",
    "axes[1].set_title(\"Average Time between Normal Clicks\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDkXd-i8nyGd"
   },
   "source": [
    "### 9. Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fHzephxZtMG5"
   },
   "outputs": [],
   "source": [
    "#Cannot be done, all variables categorical mostly categorical, correlation for numerical variables only (this case none is numerical --> only categorical, datetime)\n",
    "#Tried doing chi-square, but due to the large number of categories in each features (ip, app,device), the memory is limited and unable to do so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6huoF0Do6af"
   },
   "source": [
    "### 10. Conversion Rate between clicky IP and non clicky IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eXJea78Jtwvy"
   },
   "outputs": [],
   "source": [
    "#work with categorical varibles\n",
    "categorical = train[[\"ip\", \"app\", \"device\", \"os\", \"channel\", \"is_attributed\"]].apply(lambda x: x.astype(\"category\"))\n",
    "categorical.is_attributed = categorical.is_attributed.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-iM7AyrujBH"
   },
   "outputs": [],
   "source": [
    "#Get the number of clicks and downloads per ip and app\n",
    "agg_func_count = {'is_attributed': ['count', 'sum']} \n",
    "x = categorical.groupby([\"ip\",\"app\"]).agg(agg_func_count)\n",
    "x.columns = [\"clicks\", \"downloads\"]\n",
    "x.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vLS_kZiiu02R"
   },
   "outputs": [],
   "source": [
    "#removed ip + apps with 0 clicks\n",
    "x = x[x.clicks != 0 ]\n",
    "\n",
    "#visualisation by number clicks and downloads --> shows that those ip that downloaded the app tend to have lesser clicks on app (majority number of clicks less than 20)\n",
    "#whether the ip downloaded the app seems rather random with no clear patterns\n",
    "fig,ax = plt.subplots(figsize=(16,8))\n",
    "sns.scatterplot(data=x, x=\"clicks\", y=\"downloads\", alpha=0.5,ax=ax,s=75)\n",
    "ax.set_title(\"clicks vs downloads\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eAq27OrzxuBP"
   },
   "outputs": [],
   "source": [
    "# adding conversion rate\n",
    "x[\"conversion_rate\"] = x.downloads/x.clicks\n",
    "\n",
    "\n",
    "# visualisation by conversion rates vs clicks --> shows that conversion rate varies (app tend to download once, so depends on number of clicks)\n",
    "# but majority that downloaded tend to have high conversion rate (shown by the darker colours that indicate overlapping)\n",
    "fig,ax = plt.subplots(figsize=(16,8))\n",
    "sns.scatterplot(data=x, x=\"clicks\", y=\"conversion_rate\", hue=\"downloads\", alpha=0.3, ax=ax,s=75)\n",
    "ax.set_title(\"clicks vs conversion rate by ip and app\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JbwL0fiJWPxc"
   },
   "outputs": [],
   "source": [
    "#each ip can have multiple clicks\n",
    "train[\"ip\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MlHupAm3XWcX"
   },
   "outputs": [],
   "source": [
    "#conversion rate just by looking at ip\n",
    "#can have multiple downloads per ip\n",
    "\n",
    "x = categorical.groupby([\"ip\"]).agg(agg_func_count)\n",
    "x.columns = [\"clicks\", \"downloads\"]\n",
    "x = x.sort_values('clicks', ascending=False).reset_index()\n",
    "x[\"conversion_rate\"] = x.downloads/x.clicks\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v9JPrWaizmD-"
   },
   "outputs": [],
   "source": [
    "#comparing clicks and conversion rate for top 500 ip addresses\n",
    "#whether there is download seem pretty random, does not really seem to be related to clicks\n",
    "fig,ax = plt.subplots(figsize=(12,6))\n",
    "\n",
    "l1 = ax.plot(x.clicks[:500], color=\"red\", marker=\"o\", label=\"count\")\n",
    "ax.set_ylabel(\"clicks\")\n",
    "\n",
    "ax2=ax.twinx()\n",
    "l2 = ax2.plot(x.conversion_rate[:500], color=\"blue\", marker=\"o\", label=\"conversion\")\n",
    "ax2.set_ylabel(\"conversion rate\")\n",
    "\n",
    "lns = l1+l2\n",
    "labs = [l.get_label() for l in lns]\n",
    "ax.legend(lns, labs, loc=\"best\")\n",
    "ax.set_xlabel(\"index\")\n",
    "ax.set_title(\"Top 500 ip with most clicks\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R2qdlhEL2d5M"
   },
   "outputs": [],
   "source": [
    "#similar to previous plot visualise --> as number of clicks increases, the conversion rate decreases (make sense cause people tend to download once only thus decreases due to formula)\n",
    "# but majority that downloaded tend to have high conversion rate (shown by the darker colours that indicate overlapping)\n",
    "fig,ax = plt.subplots(figsize=(12,6))\n",
    "sns.scatterplot(data=x, x=\"clicks\", y=\"conversion_rate\", hue=\"downloads\", alpha=0.3, ax=ax,s=75)\n",
    "ax.set_title(\"clicks vs conversion rate by ip\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KpT1zca3n0w2"
   },
   "source": [
    "### 11. Channel and Conversion Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "AL3foY6WLRHQ",
    "outputId": "74c4a469-8615-4570-87e9-fc389e27c7f6"
   },
   "outputs": [],
   "source": [
    "train['click_date'] = train_datetime.dt.date\n",
    "train['dateTime'] = pd.to_datetime(train.click_date) + pd.to_timedelta(train.hour, unit='h')\n",
    "train_isAttributed = train[train['is_attributed'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TCDBcrmGZ4mg"
   },
   "outputs": [],
   "source": [
    "number_click_channel = pd.DataFrame(train.groupby(by=[\"channel\"]).size()).reset_index()\n",
    "number_click_channel = number_click_channel.rename({0: 'count'}, axis=1)\n",
    "number_click_channel.rename(columns={'count':'number_click'}, inplace=True)\n",
    "\n",
    "number_download_channel = pd.DataFrame(train_isAttributed.groupby(by=[\"channel\"]).size()).reset_index()\n",
    "number_download_channel = number_download_channel.rename({0: 'count'}, axis=1)\n",
    "number_download_channel.rename(columns={'count':'number_download'}, inplace=True)\n",
    "\n",
    "conversion_rate_channel = number_click_channel.join(number_download_channel.set_index('channel'), on=\"channel\")\n",
    "conversion_rate_channel['number_download'] = conversion_rate_channel['number_download'].fillna(0)\n",
    "conversion_rate_channel['conversion_rate'] = conversion_rate_channel['number_download']/conversion_rate_channel['number_click']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "04YdQfUrfETE",
    "outputId": "bfbd54b8-1736-4c5c-9737-1fe8b3c4f00c"
   },
   "outputs": [],
   "source": [
    "conversion_rate_channel.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "cwI0ufRsgRTl",
    "outputId": "532cc124-f654-458b-9287-ac81d669f33a"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "ax = sns.barplot(data=conversion_rate_channel, x='channel', y='conversion_rate')\n",
    "ax.set_xlabel(\"Channel\")\n",
    "ax.set_title(\"Conversion Rate\")\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "ax.xaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2AwHu3rJn-mJ"
   },
   "source": [
    "### 12. Device and Conversion Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Am9rk4RiY3E"
   },
   "outputs": [],
   "source": [
    "number_click_device = pd.DataFrame(train.groupby(by=[\"device\"]).size()).reset_index()\n",
    "number_click_device = number_click_device.rename({0: 'count'}, axis=1)\n",
    "number_click_device.rename(columns={'count':'number_click'}, inplace=True)\n",
    "\n",
    "number_download_device = pd.DataFrame(train_isAttributed.groupby(by=[\"device\"]).size()).reset_index()\n",
    "number_download_device = number_download_device.rename({0: 'count'}, axis=1)\n",
    "number_download_device.rename(columns={'count':'number_download'}, inplace=True)\n",
    "\n",
    "conversion_rate_device = number_click_device.join(number_download_device.set_index('device'), on=\"device\")\n",
    "conversion_rate_device['number_download'] = conversion_rate_device['number_download'].fillna(0)\n",
    "conversion_rate_device['conversion_rate'] = conversion_rate_device['number_download']/conversion_rate_device['number_click']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qXt1pZDri76y"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "ax = sns.barplot(data=conversion_rate_device, x='device', y='conversion_rate')\n",
    "ax.set_xlabel(\"Device\")\n",
    "ax.set_title(\"Conversion Rate\")\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(10))\n",
    "ax.xaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9nnG4eTtoI6g"
   },
   "source": [
    "### 13. Click and Conversion Rate throughout the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fD_Jl05IZpcw"
   },
   "outputs": [],
   "source": [
    "number_click_time = pd.DataFrame(train.groupby(by=[\"dateTime\"]).size()).reset_index()\n",
    "number_click_time = number_click_time.rename({0: 'count'}, axis=1)\n",
    "number_click_time.rename(columns={'count':'number_click'}, inplace=True)\n",
    "\n",
    "number_download_time= pd.DataFrame(train_isAttributed.groupby(by=[\"dateTime\"]).size()).reset_index()\n",
    "number_download_time = number_download_time.rename({0: 'count'}, axis=1)\n",
    "number_download_time.rename(columns={'count':'number_download'}, inplace=True)\n",
    "\n",
    "conversion_rate_time = number_click_time.join(number_download_time.set_index('dateTime'), on=\"dateTime\")\n",
    "conversion_rate_time['number_download'] = conversion_rate_time['number_download'].fillna(0)\n",
    "conversion_rate_time['conversion_rate'] = conversion_rate_time['number_download']/conversion_rate_time['number_click']\n",
    "conversion_rate_time = conversion_rate_time.set_index('dateTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E7sUVLs8oOLB"
   },
   "outputs": [],
   "source": [
    "# setting figure size to 12, 10\n",
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "ax2 = ax.twinx()\n",
    "# Labelling the axes and setting\n",
    "# a title\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Conversion Rate\")\n",
    "ax2.set_ylabel(\"Number of Clicks\")\n",
    "ax.set_title(\"Click and Conversion Rate Time Series\")\n",
    "\n",
    "# plotting the \"A\" column alone\n",
    "p1, = ax.plot(conversion_rate_time['conversion_rate'],  color='green', marker='x', label='Conversion Rate')\n",
    "p2, = ax2.plot(conversion_rate_time['number_click'], marker='o', label=\"Number of Clicks\")\n",
    "ax.set_xticklabels(conversion_rate_time.index, rotation=-80)\n",
    "plt.legend(handles=[p1,p2],bbox_to_anchor=(1.2, 1), loc='upper center')\n",
    "ax.yaxis.grid(color='lightgray', linestyle='dashed')\n",
    "ax2.yaxis.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TLgOpYRKCOVb"
   },
   "source": [
    "#  Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add channel, device, and dateTime conversion rate to train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train,conversion_rate_channel[['channel','conversion_rate']],on='channel')\n",
    "train.rename({'conversion_rate': 'channel_conversion_rate'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train,conversion_rate_device[['device','conversion_rate']],on='device')\n",
    "train.rename({'conversion_rate': 'device_conversion_rate'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_rate_time = conversion_rate_time.reset_index(level=0)\n",
    "train = pd.merge(train,conversion_rate_time[['dateTime','conversion_rate']],on='dateTime')\n",
    "train.rename({'conversion_rate': 'dateTime_conversion_rate'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYDC8pt032oQ"
   },
   "source": [
    "### Different combination/aggregation of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OmMf1VuV4CtF"
   },
   "outputs": [],
   "source": [
    "#functions to help aggregate and count\n",
    "\n",
    "#total counts\n",
    "def agg_counts(df, group_cols, name):\n",
    "  grp = df.groupby(group_cols).size().rename(name).to_frame().reset_index()\n",
    "  df = df.merge(grp, on=group_cols, how=\"left\")\n",
    "  return df\n",
    "\n",
    "\n",
    "#unique counts\n",
    "def agg_unique(df, group_cols, unique_col, name):\n",
    "  grp = df.groupby(group_cols)[unique_col].nunique().rename(name).to_frame().reset_index()\n",
    "  df = df.merge(grp, on=group_cols, how=\"left\")\n",
    "  return df\n",
    "\n",
    "\n",
    "#cumulative counts\n",
    "def agg_cum_count(df, group_cols, name):\n",
    "  grp = df.groupby(group_cols).cumcount()\n",
    "  df[name] = grp.values\n",
    "  return df\n",
    "\n",
    "#variance\n",
    "def agg_var(df, group_cols, counted, name):\n",
    "    grp = df.groupby(group_cols)[counted].var().rename(name).to_frame().reset_index()\n",
    "    df = df.merge(grp, on=group_cols, how='left')\n",
    "    return df\n",
    "\n",
    "#mean\n",
    "def agg_mean(df, group_cols, counted, name):\n",
    "    grp = df.groupby(group_cols)[counted].mean().rename(name).to_frame().reset_index()\n",
    "    df = df.merge(grp, on=group_cols, how='left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "h1SUxmdb6C2w",
    "outputId": "72b8bdd3-79d8-463e-c5e4-bdbe1069da47"
   },
   "outputs": [],
   "source": [
    "#data to do combi on \n",
    "\n",
    "#include date time\n",
    "import datetime\n",
    "# train_agg = train.copy()\n",
    "# train_agg[\"click_time\"] = pd.to_datetime(train[\"click_time\"])\n",
    "# train_agg[\"hour\"] = train_agg[\"click_time\"].dt.hour\n",
    "train[\"dayOfWeek\"] = train[\"click_time\"].dt.weekday\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UAHfeIbM4SOH"
   },
   "outputs": [],
   "source": [
    "#try some combinations, to see if there is a relationship\n",
    "#total counts\n",
    "train= agg_counts(train, [\"ip\", \"app\", \"device\", \"os\", \"channel\"], 'ip_app_dev_os_cha_counts')\n",
    "train = agg_counts(train, [\"ip\", \"app\", \"device\", \"os\"], 'ip_app_dev_os_counts')\n",
    "train = agg_counts(train, [\"ip\", \"app\", \"device\"], 'ip_app_dev_counts')\n",
    "train= agg_counts(train, [\"ip\", \"app\", \"os\"], 'ip_app_os_counts')\n",
    "train = agg_counts(train, [\"ip\", \"app\", \"hour\"], 'ip_app_hour_counts')\n",
    "train = agg_counts(train, [\"ip\", \"channel\"], 'ip_channel_counts')\n",
    "train = agg_counts(train, [\"ip\", \"app\"], 'ip_app_counts')\n",
    "train = agg_counts(train, [\"ip\", \"day\"], 'ip_per_day')\n",
    "train = agg_counts(train, [\"ip\"], \"ip_counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wPVzN0KC4TVC"
   },
   "outputs": [],
   "source": [
    "#unique counts\n",
    "train = agg_unique(train, [\"ip\"], \"app\", \"uniq_app_per_ip\")\n",
    "train = agg_unique(train, [\"ip\"], \"device\", \"uniq_device_per_ip\")\n",
    "train = agg_unique(train, [\"ip\"], \"channel\", \"uniq_channel_per_ip\")\n",
    "train = agg_unique(train, [\"ip\"], \"os\", \"uniq_os_per_ip\")\n",
    "train= agg_unique(train, [\"ip\", \"device\", \"os\"], \"app\", \"uniq_app_per_ip_dev_os\")\n",
    "train = agg_unique(train, [\"app\"], \"channel\", \"uniq_channel_per_app\")\n",
    "train = agg_unique(train, [\"ip\", \"day\"], \"hour\", \"uniq_hour_per_ip_day\")\n",
    "train = agg_unique(train, [\"ip\", \"app\"], \"os\", \"uniq_os_per_ip_app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YKJ-dQZQvBpj"
   },
   "outputs": [],
   "source": [
    "#cumulative counts\n",
    "train = agg_cum_count(train, [\"ip\"], \"cum_count_by_ip\")\n",
    "train = agg_cum_count(train, [\"ip\", \"device\"], \"cum_count_by_ip_device\")\n",
    "train = agg_cum_count(train, [\"ip\", \"device\",\"os\"], \"cum_count_by_ip_device_os\")\n",
    "train = agg_cum_count(train, [\"ip\", \"device\",\"os\",\"channel\"], \"cum_count_by_ip_device_os_channel\")\n",
    "train = agg_cum_count(train, [\"ip\", \"device\",\"os\",\"channel\",\"app\"], \"cum_count_by_ip_device_os_channel_app\")\n",
    "train = agg_cum_count(train, [\"app\"], \"cum_count_by_app\")\n",
    "train = agg_cum_count(train, [\"ip\", \"app\"], \"cum_count_by_ip_app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UbJeLo_UvDzZ"
   },
   "outputs": [],
   "source": [
    "#variance\n",
    "train = agg_var(train, [\"ip\",\"app\",\"channel\"], \"hour\", \"var_hour_by_ip_app_channel\")\n",
    "train = agg_var(train, [\"ip\",\"app\",\"os\"], \"hour\", \"var_hour_by_ip_app_os\")\n",
    "train = agg_var(train, [\"ip\",\"app\",\"device\"], \"hour\", \"var_hour_by_ip_app_device\")\n",
    "train = agg_var(train, [\"ip\",\"app\",\"channel\"], \"day\", \"var_day_by_ip_app_channel\")\n",
    "train = agg_var(train, [\"ip\",\"app\",\"os\"], \"day\", \"var_day_by_ip_app_os\")\n",
    "train  = agg_var(train, [\"ip\",\"app\",\"device\"], \"day\", \"var_day_by_ip_app_device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MPnc6uUOvF1f"
   },
   "outputs": [],
   "source": [
    "#mean\n",
    "train = agg_mean(train, [\"ip\",\"app\",\"channel\"], \"hour\", \"mean_hour_by_ip_app_channel\")\n",
    "train = agg_mean(train, [\"ip\",\"app\",\"os\"], \"hour\", \"mean_hour_by_ip_app_os\")\n",
    "train = agg_mean(train, [\"ip\",\"app\",\"device\"], \"hour\", \"mean_hour_by_ip_app_device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EH3kuABN6oDj"
   },
   "outputs": [],
   "source": [
    "#density plots get array of labels\n",
    "xlab = np.array(train_agg.columns[10:len(train_agg.columns)])\n",
    "\n",
    "def plot_rbyc(data_plot, xlab_arr, r, c, log = False):\n",
    "  \n",
    "  data = data_plot.copy()\n",
    "\n",
    "  if log == True:\n",
    "    data[xlab_arr] = np.log10(data_plot[xlab_arr])\n",
    "    \n",
    "  fig, axs = plt.subplots(r,c, figsize=(5*c, 2*r))\n",
    "  row, col = 0, 0\n",
    "    \n",
    "  for i in range(0, len(xlab_arr)):\n",
    "    sns.kdeplot(data=data, x=xlab_arr[i], hue=\"is_attributed\", ax=axs[row,col], fill=True)\n",
    "    if col == c-1:\n",
    "      col = 0\n",
    "      row += 1\n",
    "    else:\n",
    "      col +=1\n",
    "\n",
    "  to_be_empty = r*c - len(xlab_arr)\n",
    "  while to_be_empty > 0:\n",
    "      axs[row,col].set_visible(False)\n",
    "      if col == c-1:\n",
    "        col = 0\n",
    "        row += 1\n",
    "      else:\n",
    "        col +=1\n",
    "      to_be_empty -= 1\n",
    "      \n",
    "  plt.tight_layout()\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 912
    },
    "id": "BFny4TkY6yjg",
    "outputId": "a18d4d52-7e3f-44ef-c07e-61dcf1f204ae"
   },
   "outputs": [],
   "source": [
    "#plot all density plots -- 2 mins\n",
    "r, c = 2, 5\n",
    "total = r*c\n",
    "print(\"Different combinations of aggregating original features: \\n\")\n",
    "for i in range(0, len(xlab), total):\n",
    "  x = xlab[i:i+total]\n",
    "  plot_rbyc(train_agg, x, r, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bC7TB1KPSkd-"
   },
   "source": [
    "## Time till next click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 647
    },
    "id": "_2543cI9CRWc",
    "outputId": "8986cbc2-8532-4fce-bbcd-031c3d814839"
   },
   "outputs": [],
   "source": [
    "GROUP_BY_NEXT_CLICKS = [\n",
    "    \n",
    "    # ip with one other feature\n",
    "    {'groupby': ['ip']},\n",
    "    {'groupby': ['ip', 'app']},\n",
    "    {'groupby': ['ip', 'device']},\n",
    "    {'groupby': ['ip', 'os']},\n",
    "    {'groupby': ['ip', 'channel']},\n",
    "    \n",
    "    \n",
    "    # ip with two other features\n",
    "    {'groupby': ['ip', 'app', 'device']},\n",
    "    {'groupby': ['ip', 'app', 'os']},\n",
    "    {'groupby': ['ip', 'app', 'channel']},\n",
    "    {'groupby': ['ip', 'device', 'os']},\n",
    "    {'groupby': ['ip', 'device', 'channel']},\n",
    "    {'groupby': ['ip', 'os', 'channel']},\n",
    "\n",
    "    # ip with three other features\n",
    "    {'groupby': ['ip', 'app', 'device', 'os']},\n",
    "    {'groupby': ['ip', 'app', 'device', 'channel']},\n",
    "    {'groupby': ['ip', 'device', 'os', 'channel']},\n",
    "\n",
    "    # ip with all other features\n",
    "    {'groupby': ['ip', 'app', 'device', 'os', 'channel']}\n",
    "]\n",
    "\n",
    "# Calculate the time to next click for each group\n",
    "for spec in GROUP_BY_NEXT_CLICKS:\n",
    "    \n",
    "    # Name of new feature\n",
    "    new_feature = '{}_nextClick'.format('_'.join(spec['groupby']))    \n",
    "    \n",
    "    # Unique list of features to select\n",
    "    all_features = spec['groupby'] + ['click_time']\n",
    "    \n",
    "    # Run calculation\n",
    "    print(f\">> Grouping by {spec['groupby']}, and saving time to next click in: {new_feature}\")\n",
    "    \n",
    "    train[new_feature] = train[all_features].groupby(spec['groupby']).click_time.transform(lambda x: x.diff().shift(-1)).dt.seconds\n",
    "    \n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rxJgyRPBHOjb",
    "outputId": "6da0f8c6-f76e-48d5-e776-28c85f58ef09"
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20, 30))\n",
    "# for index, var in enumerate(train.columns[11:26]):\n",
    "#   plt.subplot(5, 3, index+1)\n",
    "#   var_0 = train[train['is_attributed']==0][var]\n",
    "#   var_1 = train[train['is_attributed']==1][var]\n",
    "#   plt.hist([var_0, var_1], label=[\"0\", \"1\"])\n",
    "#   plt.legend(loc=\"best\")\n",
    "#   plt.ylabel('Count')\n",
    "#   plt.xlabel('Time (in seconds)')\n",
    "#   plt.title(f\"Distribution of {var}\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LJIHerSgNowB",
    "outputId": "6d6b1581-9c91-4c9e-971a-cfa03cdc2c5b"
   },
   "outputs": [],
   "source": [
    "## for normal entries, they peak when the time btw clicks is ard 0s\n",
    "## on the other hand for fraud entries, they when the time btw clicks is ard 0s and 80000s (ard 1 day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hArjYTUdJn1q"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/content/drive/MyDrive/BT4012/dataset/train_FE5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "y1K3x7gQKZ5x",
    "outputId": "89f10db8-83dc-4bdd-ace2-43e89741562d"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 30))\n",
    "for index, var in enumerate(data.columns[11:26]):\n",
    "  plt.subplot(5, 3, index+1)\n",
    "  sns.kdeplot(data=data, x=var, hue=\"is_attributed\", fill=True)\n",
    "  plt.title(f\"Distribution of {var}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bS8Ipego1NI"
   },
   "source": [
    "##  Clicks on app ad before & after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "id": "3uZ3O6BMo0Ri",
    "outputId": "55ead19d-a2e0-4a92-f4a6-054ee4260442"
   },
   "outputs": [],
   "source": [
    "HISTORY_CLICKS = {\n",
    "    'identical_clicks': ['ip', 'app', 'device', 'os', 'channel'],\n",
    "    'app_clicks': ['ip', 'app']\n",
    "}\n",
    "\n",
    "# Go through different group-by combinations\n",
    "for fname, fset in HISTORY_CLICKS.items():\n",
    "    \n",
    "    # Clicks in the past\n",
    "    train['prev_'+fname] = train.groupby(fset).cumcount().rename('prev_'+fname)\n",
    "        \n",
    "    # Clicks in the future\n",
    "    train['future_'+fname] = train.iloc[::-1].groupby(fset).cumcount().rename('future_'+fname).iloc[::-1]\n",
    " \n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 893
    },
    "id": "nzti2oF59vzP",
    "outputId": "3a2da1ac-721b-4d25-fad8-60e98c16180b"
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20, 15))\n",
    "# for index, var in enumerate(train.columns[26:30]):\n",
    "#   plt.subplot(2, 2, index+1)\n",
    "#   var_0 = train[train['is_attributed']==0][var]\n",
    "#   var_1 = train[train['is_attributed']==1][var]\n",
    "#   plt.hist([var_0, var_1], label=[\"0\", \"1\"])\n",
    "#   plt.legend(loc=\"best\")\n",
    "#   plt.yscale(\"log\")\n",
    "#   plt.ylabel('Count')\n",
    "#   plt.xlabel('Number of Clicks')\n",
    "#   plt.title(f\"Distribution of {var}\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 817
    },
    "id": "mg0QZIyvLCKp",
    "outputId": "ece5ffa3-756f-47ca-aa17-007f333fdadf"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "for index, var in enumerate(data.columns[26:30]):\n",
    "  plt.subplot(2, 2, index+1)\n",
    "  sns.kdeplot(data=data, x=var, hue=\"is_attributed\", fill=True)\n",
    "  plt.title(f\"Distribution of {var}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "98rwyC78sAfb"
   },
   "source": [
    "## Confidence Rates for is_attributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 768
    },
    "id": "rGfCUSspr9kt",
    "outputId": "ec6b2993-2a65-4b90-ac4e-89d102118cb2"
   },
   "outputs": [],
   "source": [
    "ATTRIBUTION_CATEGORIES = [        \n",
    "    # V1 Features #\n",
    "    ['ip'], ['app'], ['device'], ['os'], ['channel'],\n",
    "    \n",
    "    # V2 Features #\n",
    "    ['app', 'channel'],\n",
    "    ['app', 'os'],\n",
    "    ['app', 'device'],\n",
    "    \n",
    "    # V3 Features #\n",
    "    ['channel', 'os'],\n",
    "    ['channel', 'device'],\n",
    "    ['os', 'device']\n",
    "]\n",
    "\n",
    "\n",
    "# Find frequency of is_attributed for each unique value in column\n",
    "freqs = {}\n",
    "for cols in ATTRIBUTION_CATEGORIES:\n",
    "    \n",
    "    # New feature name\n",
    "    new_feature = '_'.join(cols)+'_confRate'    \n",
    "    \n",
    "    # Perform the groupby\n",
    "    group_object = train.groupby(cols)\n",
    "    \n",
    "    # Group sizes    \n",
    "    group_sizes = group_object.size()\n",
    "    log_group = np.log(10**6) # 1000 views -> 50% confidence, 100 views -> 33% confidence \n",
    "    print(\">> Calculating confidence-weighted rate for: {}.\\n   Saving to: {}.\".format(cols, new_feature))\n",
    "    \n",
    "    # Aggregation function\n",
    "    def rate_calculation(x):\n",
    "        \"\"\"Calculate the attributed rate. Scale by confidence\"\"\"\n",
    "        rate = x.sum() / float(x.count())\n",
    "        conf = np.min([1, np.log(x.count()) / log_group])\n",
    "        return rate * conf\n",
    "    \n",
    "    # Perform the merge\n",
    "    train = train.merge(\n",
    "        group_object['is_attributed'].apply(rate_calculation).reset_index().\n",
    "        rename(index=str,columns={'is_attributed': new_feature})[cols + [new_feature]],\n",
    "        on=cols, how='left'\n",
    "    )\n",
    "    \n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7brq14N1_OVh",
    "outputId": "4090d2e1-723e-422f-9a32-265f050113c5"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 30))\n",
    "for index, var in enumerate(train.columns[30:]):\n",
    "  plt.subplot(6, 2, index+1)\n",
    "  plt.scatter(x=\"ip\", y=var, data=train[train['is_attributed']==1], color=\"orange\", alpha=0.1)\n",
    "  plt.scatter(x=\"ip\", y=var, data=train[train['is_attributed']==0], color=\"blue\", alpha=0.1)\n",
    "  plt.legend([\"1\", \"0\"], loc=\"best\")\n",
    "  plt.ylabel('Confidence Rate')\n",
    "  plt.xlabel('IP')\n",
    "  plt.title(f\"Distribution of {var}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pObPlD7-HfCF"
   },
   "outputs": [],
   "source": [
    "##save the generated features\n",
    "train.to_csv('/content/drive/MyDrive/BT4012/dataset/train_FE5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2rub5yc4k9vf"
   },
   "source": [
    "## Combining device & IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "t82GMwvolC0m",
    "outputId": "afdf3911-7192-45d3-952e-708e46ec38c5"
   },
   "outputs": [],
   "source": [
    "train['device_ip'] = train['device'].map(str) + train['ip'].map(str)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46egpREKlwIe",
    "outputId": "23280148-e73d-4231-c11c-1e9e4f23faa9"
   },
   "outputs": [],
   "source": [
    "device_ip_1 = train[train['is_attributed'] == 1]['device_ip']\n",
    "device_ip_0 = train[train['is_attributed'] == 0]['device_ip']\n",
    "\n",
    "set_device_ip_1 = set(device_ip_1.unique())\n",
    "set_device_ip_0 = set(device_ip_0.unique())\n",
    "\n",
    "print('No. of unique device_ip that downloaded app:', len(set_device_ip_1))\n",
    "print('No. of unique device_ip that did not download app:', len(set_device_ip_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PNL72d-SuZcL",
    "outputId": "4ccd6359-2fa1-4325-be76-cdf3d8a102ef"
   },
   "outputs": [],
   "source": [
    "# device_ip that always download app after clicking\n",
    "device_ip_download = set_device_ip_1.difference(set_device_ip_0)\n",
    "\n",
    "# device_ip that always do not download app after clicking\n",
    "device_ip_fraud = set_device_ip_0.difference(set_device_ip_1)\n",
    "\n",
    "print('No. of device_ip that ALWAYS downloaded app:', len(device_ip_download))\n",
    "print('No. of device_ip that NEVER downloaded app:', len(device_ip_fraud))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37vAQENrqHrn",
    "outputId": "4620d0b7-dadc-4fd6-d3fa-28873837355c"
   },
   "outputs": [],
   "source": [
    "pct_device_ip_download = (len(device_ip_download) / len(set_device_ip_1))*100\n",
    "pct_device_ip_fraud = (len(device_ip_fraud) / len(set_device_ip_0))*100\n",
    "\n",
    "print('Percentage of device_ip that ALWAYS downloaded app:', round(pct_device_ip_download, 2), '%')\n",
    "print('Percentage of device_ip that NEVER downloaded app:', round(pct_device_ip_fraud, 2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFol7slvsxNi"
   },
   "source": [
    "## Combining device & hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_aaDa-M9s9j3"
   },
   "outputs": [],
   "source": [
    "train_hour_0 = train[train[\"is_attributed\"] == 0]['hour']\n",
    "train_hour_1 = train[train[\"is_attributed\"] == 1]['hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Jc9Zjh-7tBQf",
    "outputId": "698d1332-3ebd-43df-f052-39a96b46d259"
   },
   "outputs": [],
   "source": [
    "train['device_hour'] = train['device'].map(str) + train['hour'].map(str)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-n3oQ8cGtchx",
    "outputId": "32f4ac47-8f12-4518-9c22-ade3304fc003"
   },
   "outputs": [],
   "source": [
    "device_hour_1 = train[train['is_attributed'] == 1]['device_hour']\n",
    "device_hour_0 = train[train['is_attributed'] == 0]['device_hour']\n",
    "\n",
    "set_device_hour_1 = set(device_hour_1.unique())\n",
    "set_device_hour_0 = set(device_hour_0.unique())\n",
    "\n",
    "print('No. of unique device_hour that downloaded app:', len(set_device_hour_1))\n",
    "print('No. of unique device_hour that did not download app:', len(set_device_hour_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X4f51XnxuhuF",
    "outputId": "2b21836e-2050-4958-afaf-353e42a12bc8"
   },
   "outputs": [],
   "source": [
    "# device_hour that always download app after clicking\n",
    "device_hour_download = set_device_hour_1.difference(set_device_hour_0)\n",
    "\n",
    "# device_hour that always do not download app after clicking\n",
    "device_hour_fraud = set_device_hour_0.difference(set_device_hour_1)\n",
    "\n",
    "print('No. of device_hour that ALWAYS downloaded app:', len(device_hour_download))\n",
    "print('No. of device_hour that NEVER downloaded app:', len(device_hour_fraud))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y15L8w1luxcG",
    "outputId": "36d49400-9844-458e-c84f-7ef04e33254d"
   },
   "outputs": [],
   "source": [
    "pct_device_hour_download = (len(device_hour_download) / len(set_device_hour_1))*100\n",
    "pct_device_hour_fraud = (len(device_hour_fraud) / len(set_device_hour_0))*100\n",
    "\n",
    "print('Percentage of device_hour that ALWAYS downloaded app:', round(pct_device_hour_download, 2), '%')\n",
    "print('Percentage of device_hour that NEVER downloaded app:', round(pct_device_hour_fraud, 2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See all the attributes that we have\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Drop attribute_time, click_time, dateTime, and click_date column</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['click_date', 'dateTime','attributed_time','click_time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['is_attributed']\n",
    "x_train = train.drop('is_attributed', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Convert device_ip and device_hour to numeric type as data must be int, float or bool for lightGBM</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['device_ip'] =  pd.to_numeric(x_train['device_ip'])\n",
    "x_train['device_hour'] =  pd.to_numeric(x_train['device_hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_selection import RFE\n",
    "#lightGBM model fit\n",
    "gbm = lgb.LGBMRegressor()\n",
    "gbm.fit(x_train, y_train)\n",
    "gbm.booster_.feature_importance()\n",
    "\n",
    "# importance of each attribute\n",
    "fea_imp_ = pd.DataFrame({'cols':x_train.columns, 'fea_imp':gbm.feature_importances_})\n",
    "fea_imp_.loc[fea_imp_.fea_imp > 0].sort_values(by=['fea_imp'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightGBM_top20_features = fea_imp_.loc[fea_imp_.fea_imp > 0].sort_values(by=['fea_imp'], ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_mECAApybHg"
   },
   "source": [
    "## Response Coding for Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dNOLSJDnygrU"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# what is alpha\n",
    "def get_feature_dict(alpha, feature, df):\n",
    "  value_count = train[feature].value_counts()\n",
    "  feature_dict = dict()\n",
    "  value_count_items = value_count.items()\n",
    "\n",
    "  class_0 = train['is_attributed'] == 0\n",
    "  class_1 = train['is_attributed'] == 1\n",
    "\n",
    "  for i, denominator in tqdm(value_count_items):\n",
    "    b = train[feature] == i\n",
    "    vec = []\n",
    "\n",
    "    for k in range(2):\n",
    "      if k == 0:\n",
    "        cls_cnt = train.loc[class_0 & b]\n",
    "      else:\n",
    "        cls_cnt = train.loc[class_1 & b]\n",
    "      \n",
    "      vec.append((cls_cnt.shape[0] + 10*alpha)/ (denominator + 20*alpha))\n",
    "    \n",
    "    feature_dict[i] = vec\n",
    "  \n",
    "  return feature_dict\n",
    "\n",
    "\n",
    "\n",
    "def get_feature(alpha, feature, df, feature_dict):\n",
    "  value_count = train[feature].value_counts()\n",
    "  value_count_keys = dict(value_count).keys()\n",
    "  \n",
    "  feature = []\n",
    "  for index, row in tqdm(df.iterrows()):\n",
    "    if row[feature] in value_count_keys:\n",
    "      feature.append(feature_dict[row[feature]])\n",
    "    \n",
    "    else:\n",
    "      feature.append([1/2, 1/2])\n",
    "  \n",
    "  return feature"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
